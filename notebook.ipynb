{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Major Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Machine Translation\n",
    "\n",
    "Machine Translation (MT) is the task of automatically converting one natural language into another, preserving the meaning of the input text, and producing fluent text in the output language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using EasyNMT - Easy to use, state-of-the-art Neural Machine Translation\n",
    "- https://pythonrepo.com/repo/UKPLab-EasyNMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dies ist ein Satz, den wir ins Deutsche übersetzen wollen\n",
      "['Sie können eine Liste mit Sätzen definieren.', 'Alle Sätze werden in Ihre Zielsprache übersetzt.', 'Beachten Sie, Sie können auch die Sprachen der Sätze mischen.']\n"
     ]
    }
   ],
   "source": [
    "from easynmt import EasyNMT\n",
    "model = EasyNMT('opus-mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 793k/793k [00:01<00:00, 529kB/s]  \n",
      "Downloading: 100%|██████████| 1.02M/1.02M [00:01<00:00, 882kB/s]\n",
      "Downloading: 100%|██████████| 2.00M/2.00M [00:02<00:00, 1.04MB/s]\n",
      "Downloading: 100%|██████████| 44.0/44.0 [00:00<00:00, 14.7kB/s]\n",
      "Downloading: 100%|██████████| 1.12k/1.12k [00:00<00:00, 191kB/s]\n",
      "Downloading: 100%|██████████| 292M/292M [01:22<00:00, 3.73MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "यह एक वाक्य है हम जर्मन के लिए अनुवाद करना चाहते हैं\n",
      "['Sie können eine Liste mit Sätzen definieren.', 'Alle Sätze werden in Ihre Zielsprache übersetzt.', 'Beachten Sie, Sie können auch die Sprachen der Sätze mischen.']\n"
     ]
    }
   ],
   "source": [
    "#Translate a single sentence to Hindi\n",
    "print(model.translate('This is a sentence we want to translate to German', target_lang='hi'))\n",
    "\n",
    "#Translate several sentences to German\n",
    "sentences = ['You can define a list with sentences.',\n",
    "             'All sentences are translated to your target language.',\n",
    "             'Note, you could also mix the languages of the sentences.']\n",
    "print(model.translate(sentences, target_lang='de'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मेरा नाम राघव है\n"
     ]
    }
   ],
   "source": [
    "print(model.translate(\"My name is Raghav\",target_lang='hi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  musk born june 28 1971 is an entrepreneur and\n",
      "elon reeve musk frs iln eelon born june 28 1971 is an entrepreneur and business magnate\n",
      "musk cofounded online bank xcom that same year which merged with confinity in 2000 to form paypal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing the librtaries\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import heapq\n",
    "# text from wikipedia about Elon Musk\n",
    "txt = \"Elon Reeve Musk FRS (/ˈiːlɒn/ EE-lon; born June 28, 1971) is an entrepreneur and business magnate. He is the founder, CEO, and Chief Engineer at SpaceX; early stage investor,[note 1] CEO, and Product Architect of Tesla, Inc.; founder of The Boring Company; and co-founder of Neuralink and OpenAI. A centibillionaire, Musk is one of the richest people in the world.Musk was born to a Canadian mother and South African father and raised in Pretoria, South Africa. He briefly attended the University of Pretoria before moving to Canada aged 17 to attend Queen's University. He transferred to the University of Pennsylvania two years later, where he received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University but decided instead to pursue a business career, co-founding the web software company Zip2 with his brother Kimbal. The startup was acquired by Compaq for $307 million in 1999. Musk co-founded online bank X.com that same year, which merged with Confinity in 2000 to form PayPal. The company was bought by eBay in 2002 for $1.5 billion.In 2002, Musk founded SpaceX, an aerospace manufacturer and space transport services company, of which he is CEO and CTO. In 2004, he joined electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.) as chairman and product architect, becoming its CEO in 2008. In 2006, he helped create SolarCity, a solar energy services company that was later acquired by Tesla and became Tesla Energy. In 2015, he co-founded OpenAI, a nonprofit research company that promotes friendly artificial intelligence. In 2016, he co-founded Neuralink, a neurotechnology company focused on developing brain–computer interfaces, and founded The Boring Company, a tunnel construction company. Musk has proposed the Hyperloop, a high-speed vactrain transportation system.Musk has been the subject of criticism due to unorthodox or unscientific stances and highly publicized controversies. In 2018, he was sued for defamation by a diver who advised in the Tham Luang cave rescue; a California jury ruled in favor of Musk. In the same year, he was sued by the US Securities and Exchange Commission (SEC) for falsely tweeting that he had secured funding for a private takeover of Tesla. He settled with the SEC, temporarily stepping down from his chairmanship and accepting limitations on his Twitter usage. Musk has spread misinformation about the COVID-19 pandemic and has received criticism from experts for his other views on such matters as artificial intelligence and public transport.\"\n",
    "\n",
    "#class for preprocessing and creating word embedding\n",
    "class Preprocessing:\n",
    "    #constructor\n",
    "    def __init__(self,txt):\n",
    "        # Tokenization\n",
    "        nltk.download('punkt')  #punkt is nltk tokenizer \n",
    "        # breaking text to sentences\n",
    "        tokens = nltk.sent_tokenize(txt) \n",
    "        self.tokens = tokens\n",
    "        self.tfidfvectoriser=TfidfVectorizer()\n",
    "\n",
    "    # Data Cleaning\n",
    "    # remove extra spaces\n",
    "    # convert sentences to lower case \n",
    "    # remove stopword\n",
    "    def clean_sentence(self, sentence, stopwords=False):\n",
    "        sentence = sentence.lower().strip()\n",
    "        sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "        if stopwords:\n",
    "          sentence = remove_stopwords(sentence)\n",
    "        return sentence\n",
    "\n",
    "    # store cleaned sentences to cleaned_sentences\n",
    "    def get_cleaned_sentences(self,tokens, stopwords=False):\n",
    "        cleaned_sentences = []\n",
    "        for line in tokens:\n",
    "          cleaned = self.clean_sentence(line, stopwords)\n",
    "          cleaned_sentences.append(cleaned)\n",
    "        return cleaned_sentences\n",
    "\n",
    "    #do all the cleaning\n",
    "    def cleanall(self):\n",
    "        cleaned_sentences = self.get_cleaned_sentences(self.tokens, stopwords=True)\n",
    "        cleaned_sentences_with_stopwords = self.get_cleaned_sentences(self.tokens, stopwords=False)\n",
    "        # print(cleaned_sentences)\n",
    "        # print(cleaned_sentences_with_stopwords)\n",
    "        return [cleaned_sentences,cleaned_sentences_with_stopwords]\n",
    "\n",
    "    # TF-IDF Vectorizer\n",
    "    def TFIDF(self,cleaned_sentences):\n",
    "        self.tfidfvectoriser.fit(cleaned_sentences)\n",
    "        tfidf_vectors=self.tfidfvectoriser.transform(cleaned_sentences)\n",
    "        return tfidf_vectors\n",
    "\n",
    "    #tfidf for question\n",
    "    def TFIDF_Q(self,question_to_be_cleaned):\n",
    "        tfidf_vectors=self.tfidfvectoriser.transform([question_to_be_cleaned])\n",
    "        return tfidf_vectors\n",
    "\n",
    "    # main call function\n",
    "    def doall(self):\n",
    "        cleaned_sentences, cleaned_sentences_with_stopwords = self.cleanall()\n",
    "        tfidf = self.TFIDF(cleaned_sentences)\n",
    "        return [cleaned_sentences,cleaned_sentences_with_stopwords,tfidf]\n",
    "\n",
    "#class for answering the question.\n",
    "class AnswerMe:\n",
    "    #cosine similarity\n",
    "    def Cosine(self, question_vector, sentence_vector):\n",
    "        dot_product = np.dot(question_vector, sentence_vector.T)\n",
    "        denominator = (np.linalg.norm(question_vector) * np.linalg.norm(sentence_vector))\n",
    "        return dot_product/denominator\n",
    "    \n",
    "    #Euclidean distance\n",
    "    def Euclidean(self, question_vector, sentence_vector):\n",
    "        vec1 = question_vector.copy()\n",
    "        vec2 = sentence_vector.copy()\n",
    "        if len(vec1)<len(vec2): vec1,vec2 = vec2,vec1\n",
    "        vec2 = np.resize(vec2,(vec1.shape[0],vec1.shape[1]))\n",
    "        return np.linalg.norm(vec1-vec2)\n",
    "\n",
    "    # main call function\n",
    "    def answer(self, question_vector, sentence_vector, method):\n",
    "        if method==1: return self.Euclidean(question_vector,sentence_vector)\n",
    "        else: return self.Cosine(question_vector,sentence_vector)\n",
    "\n",
    "\n",
    "def RetrieveAnswer(question_embedding, tfidf_vectors,method=1):\n",
    "  similarity_heap = []\n",
    "  if method==1: max_similarity = float('inf')\n",
    "  else: max_similarity = -1\n",
    "  index_similarity = -1\n",
    "\n",
    "  for index, embedding in enumerate(tfidf_vectors):  \n",
    "    find_similarity = AnswerMe()\n",
    "    similarity = find_similarity.answer((question_embedding).toarray(),(embedding).toarray() , method).mean()\n",
    "    if method==1:\n",
    "      heapq.heappush(similarity_heap,(similarity,index))\n",
    "    else:\n",
    "      heapq.heappush(similarity_heap,(-similarity,index))\n",
    "  return similarity_heap\n",
    "\n",
    "\n",
    "# Put Your question here\n",
    "user_question = \"musk born june 28 1971 is an entrepreneur and\"\n",
    "#define method\n",
    "method = 2\n",
    "\n",
    "preprocess = Preprocessing(txt)\n",
    "cleaned_sentences,cleaned_sentences_with_stopwords,tfidf_vectors = preprocess.doall()\n",
    "\n",
    "question = preprocess.clean_sentence(user_question, stopwords=True)\n",
    "question_embedding = preprocess.TFIDF_Q(question)\n",
    "\n",
    "similarity_heap = RetrieveAnswer(question_embedding , tfidf_vectors ,method)\n",
    "print(\"Question: \", user_question)\n",
    "\n",
    "number_of_sentences_to_print = 2\n",
    "while number_of_sentences_to_print>0 and len(similarity_heap)>0:\n",
    "  x = similarity_heap.pop(0)\n",
    "  print(cleaned_sentences_with_stopwords[x[1]])\n",
    "  number_of_sentences_to_print-=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df = pd.read_csv('./Movie Rating Prdiction/Train/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mature intelligent and highly charged melodram...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://video.google.com/videoplay?docid=211772...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: Opera (1987) Director: Dario Argento Ca...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think a lot of people just wrote this off as...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a story of two dogs and a cat looking ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Steve Carell comes into his own in his first s...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm only going to write more because it's requ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OK, it was a \"risky\" move to rent this flick, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cannibalism, a pair of cinematic references to...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is one of the great modern kung fu films....</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steve Martin looks like he's had a face lift. ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Robert Jordan is a television star. Robert Jor...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Probably the best comedy in a long time. keeps...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The earlier review is pretty much on target, w...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>It is depressing that many people don't unders...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This, like Murder She Wrote, is one of those s...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>This film is a sleeper because Rod Steiger's i...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Give director Stanley Tong of Jackie Chan's Su...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>This is another of my favorite Columbos. It sp...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This film IS brilliant...... without a doubt. ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review label\n",
       "0   mature intelligent and highly charged melodram...   pos\n",
       "1   http://video.google.com/videoplay?docid=211772...   pos\n",
       "2   Title: Opera (1987) Director: Dario Argento Ca...   pos\n",
       "3   I think a lot of people just wrote this off as...   pos\n",
       "4   This is a story of two dogs and a cat looking ...   pos\n",
       "5   Steve Carell comes into his own in his first s...   pos\n",
       "6   I'm only going to write more because it's requ...   neg\n",
       "7   OK, it was a \"risky\" move to rent this flick, ...   neg\n",
       "8   Cannibalism, a pair of cinematic references to...   pos\n",
       "9   This is one of the great modern kung fu films....   pos\n",
       "10  Steve Martin looks like he's had a face lift. ...   neg\n",
       "11  Robert Jordan is a television star. Robert Jor...   pos\n",
       "12  Probably the best comedy in a long time. keeps...   pos\n",
       "13  The earlier review is pretty much on target, w...   neg\n",
       "14  It is depressing that many people don't unders...   pos\n",
       "15  This, like Murder She Wrote, is one of those s...   pos\n",
       "16  This film is a sleeper because Rod Steiger's i...   pos\n",
       "17  Give director Stanley Tong of Jackie Chan's Su...   neg\n",
       "18  This is another of my favorite Columbos. It sp...   pos\n",
       "19  This film IS brilliant...... without a doubt. ...   pos"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df.iloc[:,0].values\n",
    "dfy = df.iloc[:,1].values\n",
    "temp = [x for x in dfy]\n",
    "y_train = [1 if x == 'pos' else 0 for x in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanin Training data\n",
    "sw = stopwords.words('english')\n",
    "sw.remove('not')\n",
    "sw = set(sw)\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def cleaning_pipeline(review):\n",
    "    words = word_tokenize(review.lower())\n",
    "    words = [ps.stem(word) for word in words if word not in sw and word.isalpha()]\n",
    "    review = \" \".join(words)\n",
    "    return review\n",
    "\n",
    "cleaned_reviews = [ cleaning_pipeline(review) for review in dfx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and cleaning testing data\n",
    "dftest = pd.read_csv('./Movie Rating Prdiction/Test/Test.csv').values\n",
    "test_reviews = dftest.reshape((-1,))\n",
    "cleaned_test_rev = [cleaning_pipeline(review) for review in test_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorization\n",
    "cv = CountVectorizer(ngram_range=(1,3))\n",
    "x_train_vect = cv.fit_transform(cleaned_reviews)\n",
    "x_test_vect = cv.transform(cleaned_test_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trainig\n",
    "mnb.fit(x_train_vect,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "prediction = mnb.predict(x_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99975"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score\n",
    "mnb.score(x_train_vect,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are many techniques available to generate extractive summarization to keep it simple, I will be using an unsupervised learning approach to find the sentences similarity and rank them. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Input text - to summarize\n",
    "text = \"\"\"There are many techniques available to generate extractive summarization to keep it simple, I will be using an unsupervised learning approach to find the sentences similarity and rank them. Summarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning. One benefit of this will be, you don’t need to train and build a model prior start using it for your project. It’s good to understand Cosine similarity to make the best use of the code you are going to see. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. Its measures cosine of the angle between vectors. The angle will be 0 if sentences are similar.\"\"\"\n",
    "\n",
    "# Tokenizing the text\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Creating a frequency table to keep the\n",
    "# score of each word\n",
    "\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "\tword = word.lower()\n",
    "\tif word in stopWords:\n",
    "\t\tcontinue\n",
    "\tif word in freqTable:\n",
    "\t\tfreqTable[word] += 1\n",
    "\telse:\n",
    "\t\tfreqTable[word] = 1\n",
    "\n",
    "# Creating a dictionary to keep the score\n",
    "# of each sentence\n",
    "sentences = sent_tokenize(text)\n",
    "sentenceValue = dict()\n",
    "\n",
    "for sentence in sentences:\n",
    "\tfor word, freq in freqTable.items():\n",
    "\t\tif word in sentence.lower():\n",
    "\t\t\tif sentence in sentenceValue:\n",
    "\t\t\t\tsentenceValue[sentence] += freq\n",
    "\t\t\telse:\n",
    "\t\t\t\tsentenceValue[sentence] = freq\n",
    "\n",
    "\n",
    "\n",
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "\tsumValues += sentenceValue[sentence]\n",
    "\n",
    "# Average value of a sentence from the original text\n",
    "\n",
    "average = int(sumValues / len(sentenceValue))\n",
    "\n",
    "# Storing sentences into our summary.\n",
    "summary = ''\n",
    "for sentence in sentences:\n",
    "\tif (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
    "\t\tsummary += \" \" + sentence\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68321d387b255d8a332b80d9cc4ccf80ca2f7bc46b6a2ad5a25ae75181723480"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlpAssnmt3.8': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
